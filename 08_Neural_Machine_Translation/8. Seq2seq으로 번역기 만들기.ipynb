{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "norman-import",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "!sudo apt-get install curl git  \n",
    "\n",
    "!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "lovely-treatment",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Mecab\n",
    "from packages import utils\n",
    "\n",
    "\n",
    "from glob import  glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binary-figure",
   "metadata": {},
   "source": [
    "## Step 1. 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "scheduled-general",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np; \n",
    "import seaborn as sns; \n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# 한글 지원 폰트\n",
    "sns.set(font='NanumGothic')\n",
    "\n",
    "# 마이너스 부호 \n",
    "\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "applicable-works",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = glob(\"./data/train/*\")\n",
    "test_data_path = glob(\"./data/test/*\")\n",
    "dev_data_path = glob(\"./data/dev/*\")\n",
    "\n",
    "def data_load(data_path):\n",
    "    result = []\n",
    "    for setences in data_path:\n",
    "        with open(setences) as f:\n",
    "            result += [f.readlines()]\n",
    "    en, ko = result        \n",
    "    data = pd.DataFrame({\"en\":en, \"ko\":ko})\n",
    "    return data\n",
    "\n",
    "train = data_load(train_data_path)\n",
    "test = data_load(test_data_path)\n",
    "dev = data_load(dev_data_path)\n",
    "\n",
    "cp_train = train.copy()\n",
    "cp_test = test.copy()\n",
    "cp_dev = dev.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-probe",
   "metadata": {},
   "source": [
    "## Step 2. 데이터 정제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranking-bradley",
   "metadata": {},
   "source": [
    "### 중복 데이터 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abstract-current",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_train = cp_train.drop_duplicates(\"en\", keep = \"first\")\n",
    "cp_train = cp_train.drop_duplicates(\"ko\", keep = \"first\")\n",
    "\n",
    "cp_test = cp_test.drop_duplicates(\"en\", keep = \"first\")\n",
    "cp_test = cp_test.drop_duplicates(\"ko\", keep = \"first\")\n",
    "\n",
    "cp_dev = cp_dev.drop_duplicates(\"en\", keep = \"first\")\n",
    "cp_dev = cp_dev.drop_duplicates(\"ko\", keep = \"first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "major-direction",
   "metadata": {},
   "source": [
    "### 공동 텍스트 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adverse-chemical",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_train[\"ko\"] = cp_train[\"ko\"].apply(lambda x : utils.text_preprocessing(x))\n",
    "cp_train[\"en\"] = cp_train[\"en\"].apply(lambda x : utils.text_preprocessing(x))\n",
    "\n",
    "cp_test[\"ko\"] = cp_test[\"ko\"].apply(lambda x : utils.text_preprocessing(x))\n",
    "cp_test[\"en\"] = cp_test[\"en\"].apply(lambda x : utils.text_preprocessing(x))\n",
    "\n",
    "cp_dev[\"ko\"] = cp_dev[\"ko\"].apply(lambda x : utils.text_preprocessing(x))\n",
    "cp_dev[\"en\"] = cp_dev[\"en\"].apply(lambda x : utils.text_preprocessing(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-typing",
   "metadata": {},
   "source": [
    "### 결측 데이터 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "colored-island",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_train = utils.remove_nan(cp_train)\n",
    "cp_test = utils.remove_nan(cp_test)\n",
    "cp_dev = utils.remove_nan(cp_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-benjamin",
   "metadata": {},
   "source": [
    "### 영어, 한국어 텍스트 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "unusual-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab = Mecab()\n",
    "def ko_pre(sentence):\n",
    "    return mecab.morphs(sentence)\n",
    "\n",
    "\n",
    "def en_pre(sentence):\n",
    "    return [\"<bos>\"] + sentence.lower().split(\" \") + [\"<eos>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "urban-disney",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_train[\"pre_ko\"] = cp_train[\"ko\"].apply(lambda x: ko_pre(x))\n",
    "cp_train[\"pre_en\"] = cp_train[\"en\"].apply(lambda x: en_pre(x))\n",
    "\n",
    "cp_train[\"pre_ko_len\"] = cp_train[\"pre_ko\"].apply(lambda x: len(x))\n",
    "cp_train[\"pre_en_len\"] = cp_train[\"pre_en\"].apply(lambda x: len(x))\n",
    "cp_train = cp_train[cp_train[\"pre_ko_len\"] <= 40]\n",
    "cp_train = cp_train[cp_train[\"pre_en_len\"] <= 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "annoying-venue",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_test[\"pre_ko\"] = cp_test[\"ko\"].apply(lambda x: ko_pre(x))\n",
    "cp_test[\"pre_en\"] = cp_test[\"en\"].apply(lambda x: en_pre(x))\n",
    "\n",
    "cp_test[\"pre_ko_len\"] = cp_test[\"pre_ko\"].apply(lambda x: len(x))\n",
    "cp_test[\"pre_en_len\"] = cp_test[\"pre_en\"].apply(lambda x: len(x))\n",
    "cp_test = cp_test[cp_test[\"pre_ko_len\"] <= 40]\n",
    "cp_test = cp_test[cp_test[\"pre_en_len\"] <= 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "frequent-companion",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_dev[\"pre_ko\"] = cp_dev[\"ko\"].apply(lambda x: ko_pre(x))\n",
    "cp_dev[\"pre_en\"] = cp_dev[\"en\"].apply(lambda x: en_pre(x))\n",
    "\n",
    "cp_dev[\"pre_ko_len\"] = cp_dev[\"pre_ko\"].apply(lambda x: len(x))\n",
    "cp_dev[\"pre_en_len\"] = cp_dev[\"pre_en\"].apply(lambda x: len(x))\n",
    "cp_dev = cp_dev[cp_dev[\"pre_ko_len\"] <= 40]\n",
    "cp_dev = cp_dev[cp_dev[\"pre_en_len\"] <= 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "coral-latino",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터셋 : (61881, 6)\n",
      "검증 데이터셋 : (806, 6)\n",
      "테스트 데이터셋 : (1546, 6)\n"
     ]
    }
   ],
   "source": [
    "print(f\"훈련 데이터셋 : {cp_train.shape}\")\n",
    "print(f\"검증 데이터셋 : {cp_dev.shape}\")\n",
    "print(f\"테스트 데이터셋 : {cp_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-truth",
   "metadata": {},
   "source": [
    "## Step 3. 데이터 토큰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "diverse-discrimination",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61881/61881 [00:00<00:00, 107445.77it/s]\n",
      "100%|██████████| 61881/61881 [00:00<00:00, 113756.64it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000 \n",
    "ko_bin_dict = utils.bin_dict(cp_train[\"pre_ko\"])\n",
    "ko_word_index, ko_index_word = utils.word_index(ko_bin_dict, vocab_size)\n",
    "x_train = utils.tokenization(cp_train[\"pre_ko\"], ko_word_index)\n",
    "\n",
    "en_bin_dict = utils.bin_dict(cp_train[\"pre_en\"])\n",
    "en_word_index, en_index_word = utils.word_index(en_bin_dict, vocab_size)\n",
    "y_train = utils.tokenization(cp_train[\"pre_en\"], en_word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "offensive-dream",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 806/806 [00:00<00:00, 113409.00it/s]\n",
      "100%|██████████| 806/806 [00:00<00:00, 144143.99it/s]\n"
     ]
    }
   ],
   "source": [
    "x_dev = utils.tokenization(cp_dev[\"pre_ko\"], ko_word_index)\n",
    "y_dev = utils.tokenization(cp_dev[\"pre_en\"], en_word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acoustic-delight",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1546/1546 [00:00<00:00, 99999.91it/s]\n",
      "100%|██████████| 1546/1546 [00:00<00:00, 151437.31it/s]\n"
     ]
    }
   ],
   "source": [
    "x_test = utils.tokenization(cp_test[\"pre_ko\"], ko_word_index)\n",
    "y_test = utils.tokenization(cp_test[\"pre_en\"], en_word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "needed-rwanda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9999, 0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(x_train), np.min(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-miller",
   "metadata": {},
   "source": [
    "## Step 4. 모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "solid-testament",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.w_dec = tf.keras.layers.Dense(units)\n",
    "        self.w_enc = tf.keras.layers.Dense(units)\n",
    "        self.w_com = tf.keras.layers.Dense(1)\n",
    "    \n",
    "    def call(self, h_enc, h_dec):\n",
    "        # h_enc shape: [batch x length x units]\n",
    "        # h_dec shape: [batch x units]\n",
    "\n",
    "        h_enc = self.w_enc(h_enc)\n",
    "        h_dec = tf.expand_dims(h_dec, 1)\n",
    "        h_dec = self.w_dec(h_dec)\n",
    "\n",
    "        score = self.w_com(tf.nn.tanh(h_dec + h_enc))\n",
    "        \n",
    "        attn = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        context_vec = attn * h_enc\n",
    "        context_vec = tf.reduce_sum(context_vec, axis=1)\n",
    "\n",
    "        return context_vec, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "sufficient-kansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(enc_units,\n",
    "                                       return_sequences=True)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.gru(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "several-large",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, h_dec, enc_out):\n",
    "        context_vec, attn = self.attention(enc_out, h_dec)\n",
    "\n",
    "        out = self.embedding(x)\n",
    "        out = tf.concat([tf.expand_dims(context_vec, 1), out], axis=-1)\n",
    "        \n",
    "        out, h_dec = self.gru(out)\n",
    "        out = tf.reshape(out, (-1, out.shape[2]))\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out, h_dec, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "lyric-convenience",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss = loss_object(real, pred)\n",
    "    \n",
    "    mask = tf.cast(mask, dtype=loss.dtype)\n",
    "    loss *= mask\n",
    "    \n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "israeli-steps",
   "metadata": {},
   "source": [
    "## Step 5. 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "running-bundle",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(src, tgt, encoder, decoder, optimizer, dec_tok):\n",
    "    bsz = src.shape[0]\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_out = encoder(src)\n",
    "        h_dec = enc_out[:, -1]\n",
    "        \n",
    "        dec_src = tf.expand_dims([dec_tok['<sos>']] * bsz, 1)\n",
    "        print(dec_src)\n",
    "        for t in range(1, tgt.shape[1]):\n",
    "            pred, h_dec, _ = decoder(dec_src, h_dec, enc_out)\n",
    "\n",
    "            loss += loss_function(tgt[:, t], pred)\n",
    "            dec_src = tf.expand_dims(tgt[:, t], 1)\n",
    "        \n",
    "    batch_loss = (loss / int(tgt.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-joseph",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "endless-netscape",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61881,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "central-binary",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = x_train[:5]\n",
    "bsz = src.shape[0]\n",
    "enc_out = encoder(src)\n",
    "h_dec = enc_out[:, -1]\n",
    "\n",
    "dec_src = tf.expand_dims([en_word_index['<sos>']] * bsz, 1)\n",
    "\n",
    "\n",
    "pred, h_dec, _ = decoder(dec_src, h_dec, enc_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "advanced-oregon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 10000), dtype=float32, numpy=\n",
       "array([[-0.00163111, -0.00153533, -0.0022845 , ..., -0.00296807,\n",
       "         0.00198207, -0.00052143],\n",
       "       [-0.00199406, -0.00148948, -0.00209272, ..., -0.00278297,\n",
       "         0.00180787, -0.00042814],\n",
       "       [-0.00133712, -0.00172316, -0.00232098, ..., -0.00306246,\n",
       "         0.00206417, -0.00054173],\n",
       "       [-0.00173508, -0.0015147 , -0.0022149 , ..., -0.00296246,\n",
       "         0.00184622, -0.00046001],\n",
       "       [-0.00219218, -0.00128892, -0.00212783, ..., -0.00260037,\n",
       "         0.00169254, -0.00041501]], dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-block",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaning-medline",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "living-responsibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def eval_step(src, tgt, encoder, decoder, dec_tok):\n",
    "    bsz = src.shape[0]\n",
    "    loss = 0\n",
    "\n",
    "    enc_out = encoder(src)\n",
    "\n",
    "    h_dec = enc_out[:, -1]\n",
    "    \n",
    "    dec_src = tf.expand_dims([dec_tok['<sos>']] * bsz, 1)\n",
    "\n",
    "    for t in range(1, tgt.shape[1]):\n",
    "        pred, h_dec, _ = decoder(dec_src, h_dec, enc_out)\n",
    "\n",
    "        loss += loss_function(tgt[:, t], pred)\n",
    "        dec_src = tf.expand_dims(tgt[:, t], 1)\n",
    "        \n",
    "    batch_loss = (loss / int(tgt.shape[1]))\n",
    "    \n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "sharp-montreal",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/967 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ExpandDims:0\", shape=(64, 1), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/967 [00:07<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-b3c09f11c967>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m                                 \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                                 \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                                 ko_word_index)\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m                     \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m                     \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautograph_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m                     \u001b[0muser_requested\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m                 ))\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/tmp5iuna0fa.py\u001b[0m in \u001b[0;36mtf__train_step\u001b[0;34m(src, tgt, encoder, decoder, optimizer, dec_tok)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                 \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    348\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    477\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1086\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    160\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/array_grad.py\u001b[0m in \u001b[0;36m_TransposeGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    808\u001b[0m   \u001b[0;34m\"\"\"Returns unshuffle(grad).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m   \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvert_permutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mtranspose\u001b[0;34m(a, perm, name, conjugate)\u001b[0m\n\u001b[1;32m   2214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mperm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2216\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtranspose_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2218\u001b[0m     \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mtranspose\u001b[0;34m(x, perm, name)\u001b[0m\n\u001b[1;32m  11593\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11594\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0;32m> 11595\u001b[0;31m         \"Transpose\", x=x, perm=perm, name=name)\n\u001b[0m\u001b[1;32m  11596\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11597\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    379\u001b[0m     \u001b[0;31m# Perform input type inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0minferred_from\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0minput_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m       \u001b[0minput_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minput_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm    # tqdm\n",
    "import random\n",
    "\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 64\n",
    "SRC_VOCAB_SIZE = 10000\n",
    "TGT_VOCAB_SIZE = 10000\n",
    "\n",
    "units = 256\n",
    "embedding_dim = 100\n",
    "\n",
    "encoder = Encoder(SRC_VOCAB_SIZE, embedding_dim, units)\n",
    "decoder = Decoder(TGT_VOCAB_SIZE, embedding_dim, units)\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    \n",
    "    idx_list = list(range(0, x_train.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm(idx_list)\n",
    "\n",
    "    for (batch, idx) in enumerate(t):\n",
    "        batch_loss = train_step(x_train[idx:idx+BATCH_SIZE],\n",
    "                                y_train[idx:idx+BATCH_SIZE],\n",
    "                                encoder,\n",
    "                                decoder,\n",
    "                                optimizer,\n",
    "                                ko_word_index)\n",
    "    \n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
    "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))\n",
    "    \n",
    "    test_loss = 0\n",
    "    \n",
    "    idx_list = list(range(0, x_dev.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm(idx_list)\n",
    "\n",
    "    for (test_batch, idx) in enumerate(t):\n",
    "        test_batch_loss = eval_step(x_dev[idx:idx+BATCH_SIZE],\n",
    "                                    y_dev[idx:idx+BATCH_SIZE],\n",
    "                                    encoder,\n",
    "                                    decoder,\n",
    "                                    ko_word_index)\n",
    "    \n",
    "        test_loss += test_batch_loss\n",
    "\n",
    "        t.set_description_str('Test Epoch %2d' % (epoch + 1))\n",
    "        t.set_postfix_str('Test Loss %.4f' % (test_loss.numpy() / (test_batch + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "catholic-wilderness",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10672.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 나는 배가 고프다\n",
      "Predicted translation: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:43: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:44: UserWarning: FixedFormatter should only be used together with FixedLocator\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate(sentence, encoder, decoder):\n",
    "    attention = np.zeros((y_train.shape[-1], x_train.shape[-1]))\n",
    "    \n",
    "    \n",
    "    inputs = utils.text_preprocessing(sentence)\n",
    "    inputs = [ko_pre(inputs)]\n",
    "    inputs = utils.tokenization(inputs, ko_word_index, max_length = x_train.shape[-1])\n",
    "    result = ''\n",
    "\n",
    "    enc_out = encoder(inputs)\n",
    "\n",
    "    dec_hidden = enc_out[:, -1]\n",
    "    dec_input = tf.expand_dims([ko_word_index['<sos>']], 0)\n",
    "\n",
    "    for t in range(y_train.shape[-1]):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = \\\n",
    "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0]).numpy()\n",
    "\n",
    "        result += ko_index_word[predicted_id] + ' '\n",
    "\n",
    "        if ko_index_word[predicted_id] == '<eos>':\n",
    "            return result, sentence, attention\n",
    "\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention\n",
    "\n",
    "\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def translate(sentence, encoder, decoder):\n",
    "    result, sentence, attention = evaluate(sentence, encoder, decoder)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    \n",
    "    attention = attention[:len(result.split()), :len(sentence.split())]\n",
    "    plot_attention(attention, sentence.split(), result.split(' '))\n",
    "\n",
    "\n",
    "translate(\"나는 배가 고프다\", encoder, decoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
