{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bridal-animal",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "!sudo apt-get install curl git  \n",
    "\n",
    "!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "floral-poster",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Mecab\n",
    "from packages import utils # package 폴더에 utils라는 script에 있는 모듈을 불러옵니다.\n",
    "\n",
    "\n",
    "from glob import  glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "encouraging-baking",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np; \n",
    "import seaborn as sns; \n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# 한글 지원 폰트\n",
    "sns.set(font='NanumGothic')\n",
    "\n",
    "# 마이너스 부호 \n",
    "\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupied-break",
   "metadata": {},
   "source": [
    "## Step 1. 데이터 로드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-saint",
   "metadata": {},
   "source": [
    "로드하는 데이터 관련 사이트 : [링크](https://sites.google.com/site/koreanparalleldata/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selective-surgeon",
   "metadata": {},
   "source": [
    "해당 데이터는 한국인 고등학생 대상 영어 번역 데이터로 다양한 종류의 주제를 가지고 만들어졌습니다.\n",
    "\n",
    "주제 \n",
    "- 뉴스 기사\n",
    "- 짧은 스토리\n",
    "- 편지\n",
    "- 광고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "quick-programmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = glob(\"./data/train/*\")\n",
    "test_data_path = glob(\"./data/test/*\")\n",
    "dev_data_path = glob(\"./data/dev/*\")\n",
    "\n",
    "def data_load(data_path):\n",
    "    result = []\n",
    "    for setences in data_path:\n",
    "        with open(setences) as f:\n",
    "            result += [f.readlines()]\n",
    "    en, ko = result        \n",
    "    data = pd.DataFrame({\"en\":en, \"ko\":ko})\n",
    "    return data\n",
    "\n",
    "train = data_load(train_data_path)\n",
    "test = data_load(test_data_path)\n",
    "dev = data_load(dev_data_path)\n",
    "\n",
    "cp_train = train.copy()\n",
    "cp_test = test.copy()\n",
    "cp_dev = dev.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "female-asthma",
   "metadata": {},
   "source": [
    "## Step 2. 데이터 정제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-breast",
   "metadata": {},
   "source": [
    "### 중복 데이터 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "detailed-reform",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_train = cp_train.drop_duplicates(\"en\", keep = \"first\")\n",
    "cp_train = cp_train.drop_duplicates(\"ko\", keep = \"first\").reset_index()\n",
    "\n",
    "cp_test = cp_test.drop_duplicates(\"en\", keep = \"first\")\n",
    "cp_test = cp_test.drop_duplicates(\"ko\", keep = \"first\").reset_index()\n",
    "\n",
    "cp_dev = cp_dev.drop_duplicates(\"en\", keep = \"first\")\n",
    "cp_dev = cp_dev.drop_duplicates(\"ko\", keep = \"first\").reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honest-suggestion",
   "metadata": {},
   "source": [
    "### 공동 텍스트 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pleased-russell",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_train[\"ko\"] = cp_train[\"ko\"].apply(lambda x : utils.text_preprocessing(x))\n",
    "cp_train[\"en\"] = cp_train[\"en\"].apply(lambda x : utils.text_preprocessing(x))\n",
    "\n",
    "cp_test[\"ko\"] = cp_test[\"ko\"].apply(lambda x : utils.text_preprocessing(x))\n",
    "cp_test[\"en\"] = cp_test[\"en\"].apply(lambda x : utils.text_preprocessing(x))\n",
    "\n",
    "cp_dev[\"ko\"] = cp_dev[\"ko\"].apply(lambda x : utils.text_preprocessing(x))\n",
    "cp_dev[\"en\"] = cp_dev[\"en\"].apply(lambda x : utils.text_preprocessing(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sweet-point",
   "metadata": {},
   "source": [
    "### 결측 데이터 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "smoking-maker",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_train = utils.remove_nan(cp_train)\n",
    "cp_test = utils.remove_nan(cp_test)\n",
    "cp_dev = utils.remove_nan(cp_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imperial-instrument",
   "metadata": {},
   "source": [
    "### 영어, 한국어 텍스트 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "happy-learning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def en_pre(sentence):\n",
    "    return \"<bos> \" + sentence.lower() + \" <eos>\"\n",
    "\n",
    "cp_train[\"en\"] = cp_train[\"en\"].apply(lambda x: en_pre(x))\n",
    "cp_dev[\"en\"] = cp_dev[\"en\"].apply(lambda x: en_pre(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selective-tooth",
   "metadata": {},
   "source": [
    "## Step 3. SentencePiece BPE 방법으로 토큰화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unusual-policy",
   "metadata": {},
   "source": [
    "### 영어와 한국어 SentencePiece model, vocab 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "important-timing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_type = \"bpe\"\n",
    "data = cp_train[\"ko\"]\n",
    "SRC_VOCAB_SIZE = 20000\n",
    "\n",
    "add = False\n",
    "train_test = \"train_ko\"\n",
    "temp_file = \"./spm_ko_train.tmp\"\n",
    "\n",
    "ko_spm = utils.SentencePiece(model_type, \n",
    "                             data, \n",
    "                             SRC_VOCAB_SIZE, \n",
    "                             add, \n",
    "                             train_test, \n",
    "                             temp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "illegal-provider",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"bpe\"\n",
    "data = cp_train[\"en\"]\n",
    "TGT_VOCAB_SIZE = 20000\n",
    "add = False\n",
    "train_test = \"train_en\"\n",
    "temp_file = \"./spm_en_train.tmp\"\n",
    "\n",
    "en_spm = utils.SentencePiece(model_type, \n",
    "                             data, \n",
    "                             TGT_VOCAB_SIZE, \n",
    "                             add, \n",
    "                             train_test, \n",
    "                             temp_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-issue",
   "metadata": {},
   "source": [
    "### 구축된 SPM모델로 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "conditional-timing",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_blank = en_spm.EncodeAsIds(\"<bos>\")[0]\n",
    "cp_train[\"pre_ko\"] = cp_train[\"ko\"].apply(lambda x: ko_spm.encode_as_ids(x))\n",
    "cp_train[\"pre_ko\"] = cp_train[\"pre_ko\"].apply(lambda x: list(filter((token_blank).__ne__,x)))\n",
    "\n",
    "cp_train[\"pre_en\"] = cp_train[\"en\"].apply(lambda x: en_spm.encode_as_ids(x))\n",
    "cp_train[\"pre_en\"] = cp_train[\"pre_en\"].apply(lambda x: list(filter((token_blank).__ne__,x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-leadership",
   "metadata": {},
   "source": [
    "### 너무 긴 문장 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-cabin",
   "metadata": {},
   "source": [
    "- 토큰화 시킨 뒤 문장의 길이가 40 이상인 데이터는 제거합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adaptive-relief",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_train[\"pre_ko_len\"] = cp_train[\"pre_ko\"].apply(lambda x: len(x))\n",
    "cp_train[\"pre_en_len\"] = cp_train[\"pre_en\"].apply(lambda x: len(x))\n",
    "\n",
    "cp_train = cp_train[cp_train[\"pre_ko_len\"] <= 40].reset_index(drop=True)\n",
    "cp_train = cp_train[cp_train[\"pre_en_len\"] <= 40].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-hygiene",
   "metadata": {},
   "source": [
    "### 모든 데이터를 길이 40인 문장으로 패딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compatible-charger",
   "metadata": {},
   "source": [
    "- 패딩 토큰의 id는 1입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "reverse-maker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1461, 18906,  1063, ...,     1,     1,     1],\n",
       "        [  453,   639, 18840, ...,     1,     1,     1],\n",
       "        [  190,  2879,   386, ...,     1,     1,     1],\n",
       "        ...,\n",
       "        [  190,   130, 19200, ...,     1,     1,     1],\n",
       "        [  622, 18852,  2204, ...,     1,     1,     1],\n",
       "        [  536,   622, 18852, ...,     1,     1,     1]], dtype=int32),\n",
       " array([[   4, 1094,   37, ...,    1,    1,    1],\n",
       "        [   4,  377,    7, ...,    1,    1,    1],\n",
       "        [   4,  573,  295, ...,    1,    1,    1],\n",
       "        ...,\n",
       "        [   4,  181,   11, ...,    1,    1,    1],\n",
       "        [   4, 1059,   45, ...,    1,    1,    1],\n",
       "        [   4,  355,  151, ...,    1,    1,    1]], dtype=int32),\n",
       " (63055, 40),\n",
       " (63055, 40))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = pad_sequences(cp_train[\"pre_ko\"], \n",
    "                        maxlen = 40,\n",
    "                        value = 1,\n",
    "                        padding = \"post\")\n",
    "y_train = pad_sequences(cp_train[\"pre_en\"], \n",
    "                        maxlen = 40, \n",
    "                        value = 1,\n",
    "                        padding = \"post\")\n",
    "\n",
    "x_train, y_train, x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welcome-wilderness",
   "metadata": {},
   "source": [
    "### 검증 데이터에도 훈련 데이터에 적용한 부분 똑같이 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "excess-defense",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1133,  1452,  2136, ...,     1,     1,     1],\n",
       "        [  224,  6560, 19066, ...,     1,     1,     1],\n",
       "        [ 2879,   289, 13910, ...,     1,     1,     1],\n",
       "        ...,\n",
       "        [  954, 14472,     1, ...,     1,     1,     1],\n",
       "        [ 2225, 17003,    58, ...,     1,     1,     1],\n",
       "        [ 1720,  1847, 19510, ...,     1,     1,     1]], dtype=int32),\n",
       " array([[    4,   792,  1149, ...,     1,     1,     1],\n",
       "        [    4,    11,  1698, ...,     1,     1,     1],\n",
       "        [    4,    93,   351, ...,     1,     1,     1],\n",
       "        ...,\n",
       "        [    4,   582, 19995, ...,     1,     1,     1],\n",
       "        [    4,   517,   480, ...,     5,     1,     1],\n",
       "        [    4,  2483, 15777, ...,     1,     1,     1]], dtype=int32),\n",
       " (812, 40),\n",
       " (812, 40))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp_dev[\"pre_ko\"] = cp_dev[\"ko\"].apply(lambda x: ko_spm.encode_as_ids(x))\n",
    "cp_dev[\"pre_ko\"] = cp_dev[\"pre_ko\"].apply(lambda x: list(filter((token_blank).__ne__,x)))\n",
    "cp_dev[\"pre_en\"] = cp_dev[\"en\"].apply(lambda x: en_spm.encode_as_ids(x))\n",
    "cp_dev[\"pre_en\"] = cp_dev[\"pre_en\"].apply(lambda x: list(filter((token_blank).__ne__,x)))\n",
    "\n",
    "cp_dev[\"pre_ko_len\"] = cp_dev[\"pre_ko\"].apply(lambda x: len(x))\n",
    "cp_dev[\"pre_en_len\"] = cp_dev[\"pre_en\"].apply(lambda x: len(x))\n",
    "\n",
    "cp_dev = cp_dev[cp_dev[\"pre_ko_len\"] <= 40].reset_index(drop=True)\n",
    "cp_dev = cp_dev[cp_dev[\"pre_en_len\"] <= 40].reset_index(drop=True)\n",
    "\n",
    "x_dev = pad_sequences(cp_dev[\"pre_ko\"], \n",
    "                      maxlen = 40, \n",
    "                      value = 1,\n",
    "                      padding = \"post\")\n",
    "y_dev = pad_sequences(cp_dev[\"pre_en\"], \n",
    "                      maxlen = 40, \n",
    "                      value = 1,\n",
    "                      padding = \"post\")\n",
    "\n",
    "x_dev, y_dev, x_dev.shape, y_dev.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "official-instruction",
   "metadata": {},
   "source": [
    "## Step 4. 모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "significant-secret",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.w_dec = tf.keras.layers.Dense(units)\n",
    "        self.w_enc = tf.keras.layers.Dense(units)\n",
    "        self.w_com = tf.keras.layers.Dense(1)\n",
    "    \n",
    "    def call(self, h_enc, h_dec):\n",
    "        # h_enc shape: [batch x length x units]\n",
    "        # h_dec shape: [batch x units]\n",
    "\n",
    "        h_enc = self.w_enc(h_enc) \n",
    "        h_dec = tf.expand_dims(h_dec, 1) # [batch, 1, units]\n",
    "        h_dec = self.w_dec(h_dec)\n",
    "        \n",
    "        # score shape : [batch, length, units]\n",
    "        score = self.w_com(tf.nn.tanh(h_dec + h_enc))\n",
    "        \n",
    "        # attn shape : [batch, length, 1]\n",
    "        attn = tf.nn.softmax(score, axis=1)\n",
    "        \n",
    "        # context_vec.shape : [batch, length, units]\n",
    "        context_vec = attn * h_enc\n",
    "        # context_vec.shape : [batch, units]\n",
    "        context_vec = tf.reduce_sum(context_vec, axis=1)\n",
    "\n",
    "        return context_vec, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ethical-programming",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(enc_units,\n",
    "                                       return_sequences=True)\n",
    "        self.dropout = tf.keras.layers.Dropout(0.2)\n",
    "        \n",
    "    def call(self, x):\n",
    "        # embedding shape : [batch, length, embedding_dim]\n",
    "        out = self.embedding(x) \n",
    "        # gru shape : [batch, length, enc_units]\n",
    "        out = self.gru(out) \n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "excellent-canadian",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "        self.bn = tf.keras.layers.BatchNormalization()\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "    # 학습과정에서 문장이 통째로가 아닌 문장에 있는 한 단어씩 들어옴 (batch, 1)\n",
    "    def call(self, x, h_dec, enc_out):\n",
    "        # enc_out.shape = [batch, length, units]\n",
    "        # h_dec shape = [batch, units]\n",
    "        context_vec, attn = self.attention(enc_out, h_dec) # context_vec.shape : [batch, units]\n",
    "        \n",
    "        out = self.embedding(x) # out shape = [batch, 1, embedding_dim]\n",
    "        out = tf.concat([tf.expand_dims(context_vec, 1), out], axis=-1) # out shape = [batch, 1, embedding_dim + units]\n",
    "        out, h_dec = self.gru(out) # out shape = [batch, 1, units]\n",
    "        out = self.bn(out)\n",
    "        out = tf.reshape(out, (-1, out.shape[2])) # out shape = [batch, units]\n",
    "        out = self.fc(out) # out shape = [batch, vocab_size]\n",
    "        return out, h_dec, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "mediterranean-vertex",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss = loss_object(real, pred)\n",
    "    \n",
    "    mask = tf.cast(mask, dtype=loss.dtype)\n",
    "    loss *= mask\n",
    "    \n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-advocate",
   "metadata": {},
   "source": [
    "## Step 5. 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "indian-affairs",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(src, tgt, encoder, decoder, optimizer, dec_tok):\n",
    "    bsz = src.shape[0]\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_out = encoder(src)\n",
    "        h_dec = enc_out[:, -1]\n",
    "        # encode_as_ids('<bos>') = (9970, 4)[-1] => 4\n",
    "        dec_src = tf.expand_dims([dec_tok.encode_as_ids('<bos>')[-1]] * bsz, 1)\n",
    "        for t in range(1, tgt.shape[1]):\n",
    "            pred, h_dec, _ = decoder(dec_src, h_dec, enc_out)\n",
    "\n",
    "            loss += loss_function(tgt[:, t], pred)\n",
    "            dec_src = tf.expand_dims(tgt[:, t], 1)\n",
    "        \n",
    "    batch_loss = (loss / int(tgt.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bibliographic-closure",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def eval_step(src, tgt, encoder, decoder, dec_tok):\n",
    "    bsz = src.shape[0]\n",
    "    loss = 0\n",
    "\n",
    "    enc_out = encoder(src)\n",
    "\n",
    "    h_dec = enc_out[:, -1]\n",
    "    \n",
    "    dec_src = tf.expand_dims([dec_tok.encode_as_ids('<bos>')[-1]] * bsz, 1)\n",
    "\n",
    "    for t in range(1, tgt.shape[1]):\n",
    "        pred, h_dec, _ = decoder(dec_src, h_dec, enc_out)\n",
    "\n",
    "        loss += loss_function(tgt[:, t], pred)\n",
    "        dec_src = tf.expand_dims(tgt[:, t], 1)\n",
    "        \n",
    "    batch_loss = (loss / int(tgt.shape[1]))\n",
    "    \n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "tutorial-stanley",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence, encoder, decoder, enc_tok, dec_tok):\n",
    "    attention = np.zeros((y_train.shape[-1], x_train.shape[-1]))\n",
    "    \n",
    "    \n",
    "    inputs = [ko_spm.EncodeAsIds(sentence)]\n",
    "    inputs = pad_sequences(inputs, \n",
    "                           maxlen = 40, \n",
    "                           value = 1,\n",
    "                           padding = \"pre\")\n",
    "    result = ''\n",
    "    \n",
    "    # enc_out : [batch, length, units]\n",
    "    enc_out = encoder(inputs)\n",
    "    \n",
    "    # dec_hidden : [batch, units]\n",
    "    dec_hidden = enc_out[:, -1]\n",
    "    # dec_input : [batch, 1]\n",
    "    dec_input = tf.expand_dims([enc_tok.encode_as_ids('<bos>')[-1]], 0)\n",
    "\n",
    "    for t in range(y_train.shape[-1]):\n",
    "        # predictions : [batch, vocab_size]\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention[t] = attention_weights.numpy()\n",
    "        \n",
    "        # predicted_id : numpy.int64\n",
    "        predicted_id = \\\n",
    "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0]).numpy()\n",
    "        result += dec_tok.DecodeIds([int(predicted_id)]) + ' '\n",
    "\n",
    "        if dec_tok.DecodeIds([int(predicted_id)]) == '<eos>':\n",
    "            return result, sentence, attention\n",
    "\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention\n",
    "\n",
    "\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def translate(sentence, encoder, decoder, enc_tok, dec_tok):\n",
    "    result, sentence, attention = evaluate(sentence, encoder, decoder, enc_tok, dec_tok)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    \n",
    "#    attention = attention[:len(result.split()), :len(sentence.split())]\n",
    "#    plot_attention(attention, sentence.split(), result.split(' '))\n",
    "# translate(\"나는 배가 고프다\", encoder, decoder, ko_spm, en_spm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "passing-bhutan",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  1: 100%|██████████| 493/493 [07:31<00:00,  1.09it/s, Loss 4.9693]\n",
      "Test Epoch  1: 100%|██████████| 7/7 [00:22<00:00,  3.15s/it, Test Loss 4.8090]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/493 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  2: 100%|██████████| 493/493 [06:16<00:00,  1.31it/s, Loss 4.8435]\n",
      "Test Epoch  2: 100%|██████████| 7/7 [00:01<00:00,  4.80it/s, Test Loss 4.7874]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/493 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  3: 100%|██████████| 493/493 [06:21<00:00,  1.29it/s, Loss 4.8240]\n",
      "Test Epoch  3: 100%|██████████| 7/7 [00:01<00:00,  4.73it/s, Test Loss 4.7717]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/493 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  4: 100%|██████████| 493/493 [06:17<00:00,  1.31it/s, Loss 4.8160]\n",
      "Test Epoch  4: 100%|██████████| 7/7 [00:01<00:00,  4.80it/s, Test Loss 4.7686]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/493 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  5: 100%|██████████| 493/493 [06:16<00:00,  1.31it/s, Loss 4.8117]\n",
      "Test Epoch  5: 100%|██████████| 7/7 [00:01<00:00,  4.78it/s, Test Loss 4.7644]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/493 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  6: 100%|██████████| 493/493 [06:16<00:00,  1.31it/s, Loss 4.8094]\n",
      "Test Epoch  6: 100%|██████████| 7/7 [00:01<00:00,  4.82it/s, Test Loss 4.7612]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/493 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  7: 100%|██████████| 493/493 [06:16<00:00,  1.31it/s, Loss 4.8231]\n",
      "Test Epoch  7: 100%|██████████| 7/7 [00:01<00:00,  4.82it/s, Test Loss 4.7666]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/493 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  8: 100%|██████████| 493/493 [06:18<00:00,  1.30it/s, Loss 4.8105]\n",
      "Test Epoch  8: 100%|██████████| 7/7 [00:01<00:00,  4.76it/s, Test Loss 4.7630]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/493 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  9: 100%|██████████| 493/493 [06:21<00:00,  1.29it/s, Loss 4.8066]\n",
      "Test Epoch  9: 100%|██████████| 7/7 [00:01<00:00,  4.81it/s, Test Loss 4.7574]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/493 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 493/493 [06:16<00:00,  1.31it/s, Loss 4.8042]\n",
      "Test Epoch 10: 100%|██████████| 7/7 [00:01<00:00,  4.84it/s, Test Loss 4.7552]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/493 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 493/493 [06:16<00:00,  1.31it/s, Loss 4.7889]\n",
      "Test Epoch 11: 100%|██████████| 7/7 [00:01<00:00,  4.81it/s, Test Loss 4.7357]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: the <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: the <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: the <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/493 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: the <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 493/493 [06:17<00:00,  1.31it/s, Loss 4.3212]\n",
      "Test Epoch 12: 100%|██████████| 7/7 [00:01<00:00,  4.83it/s, Test Loss 3.8166]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: the first <eos> \n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: the first <eos> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/493 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: the first <eos> \n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: the first <eos> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 493/493 [06:17<00:00,  1.30it/s, Loss 3.7190]\n",
      "Test Epoch 13: 100%|██████████| 7/7 [00:01<00:00,  4.77it/s, Test Loss 3.5670]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: the u s <eos> \n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: the u s <eos> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/493 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: the u s <eos> \n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: the u s <eos> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 493/493 [06:18<00:00,  1.30it/s, Loss 3.5127]\n",
      "Test Epoch 14: 100%|██████████| 7/7 [00:01<00:00,  4.79it/s, Test Loss 3.4103]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: the united states <eos> \n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: the first time <eos> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/493 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: the first time <eos> \n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: the first <eos> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 493/493 [06:18<00:00,  1.30it/s, Loss 3.3512]\n",
      "Test Epoch 15: 100%|██████████| 7/7 [00:01<00:00,  4.75it/s, Test Loss 3.2993]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: obama ' s a new york <eos> \n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: the first time <eos> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/493 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: the first time <eos> \n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: the country <eos> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 493/493 [06:18<00:00,  1.30it/s, Loss 3.2090]\n",
      "Test Epoch 16: 100%|██████████| 7/7 [00:01<00:00,  4.79it/s, Test Loss 3.2009]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: obama ' s <eos> \n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: the first time <eos> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/493 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: the first time <eos> \n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: the city <eos> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 493/493 [06:18<00:00,  1.30it/s, Loss 3.0917]\n",
      "Test Epoch 17: 100%|██████████| 7/7 [00:01<00:00,  4.78it/s, Test Loss 3.1267]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: obama <eos> \n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: the first time <eos> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/493 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: the first time <eos> \n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: the first time <eos> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 493/493 [06:17<00:00,  1.30it/s, Loss 2.9636]\n",
      "Test Epoch 18: 100%|██████████| 7/7 [00:01<00:00,  4.78it/s, Test Loss 3.0640]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: obama <eos> \n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: the first time <eos> \n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: the first time <eos> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/493 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: the number of the city of the city of the city of the city of the city of the city of the city of the city of the city of the city of the city of the city of the \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 493/493 [06:19<00:00,  1.30it/s, Loss 2.8550]\n",
      "Test Epoch 19: 100%|██████████| 7/7 [00:01<00:00,  4.80it/s, Test Loss 3.0217]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: obama <eos> \n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: in the city <eos> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/493 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: the white house <eos> \n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: in the dead <eos> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 493/493 [06:18<00:00,  1.30it/s, Loss 2.7559]\n",
      "Test Epoch 20: 100%|██████████| 7/7 [00:01<00:00,  4.78it/s, Test Loss 2.9919]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: in the first time <eos> \n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: the first time <eos> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/493 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: the name <eos> \n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: in the crash <eos> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 493/493 [06:18<00:00,  1.30it/s, Loss 2.6610]\n",
      "Test Epoch 21: 100%|██████████| 7/7 [00:01<00:00,  4.74it/s, Test Loss 2.9739]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: in the first lady <eos> \n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: the most famous for the city <eos> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/493 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: the fda ' s <eos> \n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: in the city of death <eos> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 493/493 [06:19<00:00,  1.30it/s, Loss 2.5697]\n",
      "Test Epoch 22: 100%|██████████| 7/7 [00:01<00:00,  4.74it/s, Test Loss 2.9733]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: in the first time <eos> \n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: in the street <eos> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/493 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: there <eos> \n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: in the city of death <eos> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 493/493 [06:18<00:00,  1.30it/s, Loss 2.4823]\n",
      "Test Epoch 23: 100%|██████████| 7/7 [00:01<00:00,  4.75it/s, Test Loss 2.9735]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: in the same <eos> \n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: in the street <eos> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/493 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: in the same <eos> \n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: in the past two weeks <eos> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 493/493 [06:18<00:00,  1.30it/s, Loss 2.3961]\n",
      "Test Epoch 24: 100%|██████████| 7/7 [00:01<00:00,  4.77it/s, Test Loss 2.9854]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: in <eos> \n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: in <eos> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/493 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: in the same time <eos> \n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: in the case of the dead were killed <eos> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 493/493 [06:19<00:00,  1.30it/s, Loss 2.3109]\n",
      "Test Epoch 25: 100%|██████████| 7/7 [00:01<00:00,  4.75it/s, Test Loss 3.0082]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: in <eos> \n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: in <eos> \n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: in <eos> \n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: in the same time <eos> \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm    # tqdm\n",
    "import random\n",
    "\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "\n",
    "units = 512\n",
    "embedding_dim = 256\n",
    "\n",
    "encoder = Encoder(SRC_VOCAB_SIZE, embedding_dim, units)\n",
    "decoder = Decoder(TGT_VOCAB_SIZE, embedding_dim, units)\n",
    "\n",
    "history_train_loss = []\n",
    "history_test_loss = []\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    \n",
    "    idx_list = list(range(0, x_train.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm(idx_list)\n",
    "\n",
    "    for (batch, idx) in enumerate(t):\n",
    "        batch_loss = train_step(x_train[idx:idx+BATCH_SIZE],\n",
    "                                y_train[idx:idx+BATCH_SIZE],\n",
    "                                encoder,\n",
    "                                decoder,\n",
    "                                optimizer,\n",
    "                                en_spm)\n",
    "    \n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
    "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))\n",
    "    \n",
    "    \n",
    "    test_loss = 0\n",
    "    \n",
    "    idx_list = list(range(0, x_dev.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm(idx_list)\n",
    "\n",
    "    for (test_batch, idx) in enumerate(t):\n",
    "        test_batch_loss = eval_step(x_dev[idx:idx+BATCH_SIZE],\n",
    "                                    y_dev[idx:idx+BATCH_SIZE],\n",
    "                                    encoder,\n",
    "                                    decoder,\n",
    "                                    en_spm)\n",
    "    \n",
    "        test_loss += test_batch_loss\n",
    "    \n",
    "        t.set_description_str('Test Epoch %2d' % (epoch + 1))\n",
    "        t.set_postfix_str('Test Loss %.4f' % (test_loss.numpy() / (test_batch + 1)))\n",
    "\n",
    "    history_train_loss += [total_loss.numpy()]\n",
    "    history_test_loss += [test_loss.numpy()]\n",
    "    \n",
    "    sentence = \"오바마는 대통령이다.\"\n",
    "    translate(sentence, encoder, decoder, ko_spm, en_spm)\n",
    "    sentence = \"시민들은 도시 속에 산다.\"\n",
    "    translate(sentence, encoder, decoder, ko_spm, en_spm)\n",
    "    sentence = \"커피는 필요 없다.\"\n",
    "    translate(sentence, encoder, decoder, ko_spm, en_spm)\n",
    "    sentence = \"일곱 명의 사망자가 발생했다.\"\n",
    "    translate(sentence, encoder, decoder, ko_spm, en_spm)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "interesting-event",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_train_loss, label = \"train_loss\")\n",
    "plt.plot(history_test_loss, label = \"test_loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Seq2seq based Bahdana attention learning process\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
