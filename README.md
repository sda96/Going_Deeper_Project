# Going_Deeper_Project
AIFFEL 교육과정 중 NLP Going Deeper Project와 내용 정리

## 첫 번째 프로젝트 : 자연어 처리의 시작 임베딩 - [블로그 정리글](https://sda96.github.io/2021-12/NLP_1day)
- [word2vec](https://arxiv.org/pdf/1301.3781.pdf)
- [FastText](https://arxiv.org/pdf/1607.04606.pdf)
- [GloVe](https://nlp.stanford.edu/pubs/glove.pdf)
- [Byte Pair Encoding](https://arxiv.org/pdf/1508.07909.pdf)
- [SentencePiece](https://arxiv.org/pdf/1808.06226.pdf)
- [ELMo](https://arxiv.org/pdf/1802.05365.pdf)

한국어 사전 학습된 임베딩 벡터 다운로드
- https://github.com/Kyubyong/wordvectors


## 두 번째 프로젝트 : 단어장의 크기에 따른 모델 성능 비교 - [블로그 정리글](https://sda96.github.io/2021-12/machine_learning_models_preview)
사용된 머신 러닝 모델
- [MultiNB](https://www.youtube.com/watch?v=3JWLIV3NaoQ)
- [ComNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.ComplementNB.html)
- [Logistic Regression](https://sda96.github.io/2021-10/classification_problem)
- [Support Vector Classifier](https://blog.naver.com/tjdudwo93/221051481147)
- [Decision Tree](https://datascienceschool.net/03%20machine%20learning/12.01%20%EC%9D%98%EC%82%AC%EA%B2%B0%EC%A0%95%EB%82%98%EB%AC%B4.html)
- [Random Forest](https://www.tibco.com/reference-center/what-is-a-random-forest)
- [Gradient Boosting Tree](https://bkshin.tistory.com/entry/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-15-Gradient-Boost)
- [Voting](https://stats.stackexchange.com/questions/349540/hard-voting-soft-voting-in-ensemble-based-methods)

## 세 번째 프로젝트 : 임베딩내의 편향성 계산
- [임베딩 벡터 편향성 문제 제기](https://arxiv.org/pdf/1607.06520.pdf)
- [WEAT](https://arxiv.org/pdf/1608.07187.pdf)

영어 사전 학습된 임베딩 벡터 다운로드
- https://drive.google.com/u/0/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM&export=download


## 네 번째, 다섯 번째 프로젝트 : Seq2seq, Transformer 모델로 번역기 만들기
- [Seq2seq](https://arxiv.org/pdf/1409.3215.pdf)
- [Transformer](https://arxiv.org/pdf/1706.03762.pdf)
