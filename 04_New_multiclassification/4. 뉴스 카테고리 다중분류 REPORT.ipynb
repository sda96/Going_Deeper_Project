{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "infectious-moment",
   "metadata": {},
   "source": [
    "## 1. 서론"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abroad-kernel",
   "metadata": {},
   "source": [
    "이전 프로젝트에서는 nsmc 데이터셋을 사용하여 긍정인지 부정인지를 분류하는 이진 분류 모델을 학습하였습니다. \n",
    "\n",
    "해당 글에서는 영어로된 로이터 뉴스 데이터를 활용하여 46개의 클래스를 분류하는 다중 분류 문제를 해결할 것이며 해당 문제를 해결하기 위한 모델을 머신러닝 모델과 딥러닝 모델로 나누어서 진행하고 각 모델들의 성능을 단어장의 크기(vocab_size)에 따라서 얼마나 차이가 있는지 비교하여 가장 좋은 퍼포먼스를 낸 모델을 찾아보겠습니다.\n",
    "\n",
    "머신러닝 모델에서 사용되어진 모델, 알고리즘을 다음과 같습니다.\n",
    "1. Multinomail Naive Bayes (MultiNB) \n",
    "2. Complement Naive Bayes (CNB)\n",
    "3. Logistic Regression (LR)\n",
    "4. Support Vector Classifier (SVC)\n",
    "5. Decision Tree (DT)\n",
    "6. Random Forest (RF)\n",
    "7. Gradient Boosting Tree (GBT)\n",
    "8. Voting \n",
    "\n",
    "딥러닝 모델에서 사용되어진 모델은 다음과 같습니다.  \n",
    "1. Convlutiona 1D (Conv1D)\n",
    "\n",
    "비교할 단어장의 크기는 다음과 같습니다.\n",
    "1. 단어장의 크기 5,000개의 단어\n",
    "2. 단어장의 크기 10,000개의 단어\n",
    "3. 사용할 수 있는 모든 단어"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-relation",
   "metadata": {},
   "source": [
    "## 2. 본론"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable-greenhouse",
   "metadata": {},
   "source": [
    "현재 로이터 뉴스 데이터는 46개의 클래스로 분류가 되지만 각 클래스마다보유하고 있는 데이터의 개수가 굉장히 불균형이 크기 때문에 각 모델들의 성능을 확인하는 지표로 정확도(accuracy)가 아닌 가중치가 적용된 F1-score(weighted f1-score)를 사용하겠습니다.\n",
    "\n",
    "그리고 머신러닝 모델에는 TF-IDF로 벡터화를 시킨 데이터를 입력으로 넣고 딥러닝 모델에는 로이터 뉴스 데이터에서 가져온 벡터 그대로 입력으로 넣겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-dialogue",
   "metadata": {},
   "source": [
    "### 2.2 단어장의 크기에 따른 모델의 성능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continent-korean",
   "metadata": {},
   "source": [
    "|모델| vocab_size = 5,000 | vocab_size = 10,000 | vocab_size = ALL |\n",
    "|-|-|-|-|\n",
    "|MultiNB|0.60|0.58|**0.50**|\n",
    "|CNB|0.75|0.75|0.73|\n",
    "|LR|**0.80**|**0.80**|**0.81**|\n",
    "|SVC|0.76|0.77|0.77|\n",
    "|DT|**0.57**|**0.58**|0.58|\n",
    "|RF|0.68|0.64|0.62|\n",
    "|GBT|0.77|0.76|0.76|\n",
    "|Voting|0.69|0.70|0.70|\n",
    "|Conv1D|0.69|0.70|0.70|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-grace",
   "metadata": {},
   "source": [
    "본 노트북에서는 각 모델들의 성능에 대한 최종 결과만 정리해 놓았으며 좀 더 자세한 내용과 코드는 단어장의 크기에 따라서 따로 분류를 해놓았습니다. 좀 더 자세한 내용을 보고 싶으면 아래의 링크들을 사용하시면 되겠습니다.\n",
    "- [단어장이 5,000개인 경우의 실습 파일.ipynb](https://github.com/sda96/Going_Deeper_Project/blob/main/04_New_multiclassification/02_Going_Deeper_Project_5000.ipynb)\n",
    "- [단어장이 10,000개인 경우의 실습 파일.ipynb](https://github.com/sda96/Going_Deeper_Project/blob/main/04_New_multiclassification/02_Going_Deeper_Project_10000.ipynb)\n",
    "- [단어장이 모든 단어를 사용한 경우의 실습 파일.ipynb](https://github.com/sda96/Going_Deeper_Project/blob/main/04_New_multiclassification/02_Going_Deeper_Project_ALL.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-failing",
   "metadata": {},
   "source": [
    "## 3. 결론"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "better-premises",
   "metadata": {},
   "source": [
    "전체적으로 vocab_size가 커질수록 Naive Bayes 모델과 트리 기반의 모델의  경우 성능이 떨어지는 현상이 발견되었습니다.\n",
    "- Naive Bayes 모델의 성능이 떨어지는 이유는 모델이 베이즈 정리를 기반으로 클래스를 분류하기 때문에 입력되는 변수의 경우의 수가 많아질수록 올바른 클래스를 분류할 확률이 낮아지기 때문이라고 생각합니다.\n",
    "- 트리모델 또한 분류되는 가지의 수가 많아지기 너무 많아지기 때문에 과대적합 문제가 발생한거라고 생각합니다.\n",
    "\n",
    "하지만 Logistic Regression 모델과 Support Vector 모델의 경우 vocab_size가 커질수록 성능이 개선되는 모습을 보여주었습니다.\n",
    "- 해당 모델들의 성능이 개선되는 이유는 OvR 알고리즘이 영향을 주었다고 생각합니다. 왜냐하면 결국에는 LR과 SVC는 0번 클래스냐? 아니냐? 로 접근을 하고 이러한 모델을 클래스의 개수만큼 만들어 반환하기 때문입니다.\n",
    "\n",
    "딥러닝 모델또한 vocab_size가 커질수록 성능이 상승하였습니다.\n",
    "- 해당 모델이 성능이 좋아진 이유는 임베딩시킬 단어의 수가 늘어나며 고려할 수 있는 경우의 수가 증가하였기 떄문이라고 생각합니다.\n",
    "\n",
    "결국 분석에 목적에 맞게 vocab_size에 따라서 가장 성능이 좋게 나온 모델은 Logistc Regression 모델로 해당 모델을 선정하는 것이 가장 타당합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
